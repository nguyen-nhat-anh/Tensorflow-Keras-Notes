{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1216 11:40:06.164047 25212 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(28, 28, 3))\n",
    "hidden_layer = tf.keras.layers.Dense(5)(input_layer)\n",
    "output_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
    "\n",
    "model = tf.keras.models.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_updates_for(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'batch_normalization/AssignMovingAvg/AssignSubVariableOp' type=AssignSubVariableOp>,\n",
       " <tf.Operation 'batch_normalization/AssignMovingAvg_1/AssignSubVariableOp' type=AssignSubVariableOp>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_updates_for(model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_mean, moving_variance = set(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)) - set(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(model.input, training=True)\n",
    "y_true = tf.placeholder(shape=(None, 28, 28, 5), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras APIs handle BatchNormalization updates to the moving_mean and moving_variance as part of their `fit()` and `evaluate()` loops. However, if a custom training loop is used with an instance of `Model`, these updates need to be explicitly included. Here's a simple example of how it can be done\n",
    "\n",
    "```python\n",
    "# model is an instance of Model that contains BatchNormalization layer.\n",
    "update_ops = model.get_updates_for(None) + model.get_updates_for(model.inputs)\n",
    "train_op = optimizer.minimize(loss)\n",
    "train_op = tf.group([train_op, update_ops])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_ops = model.get_updates_for(None) + model.get_updates_for(model.inputs)\n",
    "train_op = optimizer.minimize(loss, var_list=model.trainable_variables)\n",
    "train_op = tf.group([train_op, update_ops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9905418  0.99049205 0.99014586 0.99012387 0.9907512 ]\n",
      "[0.9811823  0.98107016 0.9803861  0.980346   0.98159504]\n",
      "[0.9719129  0.97175294 0.97072697 0.9706639  0.97253674]\n",
      "[0.96274096 0.96252525 0.961162   0.9610792  0.9635669 ]\n",
      "[0.9536593  0.95338464 0.9516894  0.95158994 0.9546872 ]\n",
      "[0.9446627  0.9443322  0.94231015 0.94219476 0.94589305]\n",
      "[0.93575495 0.93536633 0.9330243  0.932892   0.9371808 ]\n",
      "[0.9269324  0.92648613 0.9238289  0.9236804  0.92855275]\n",
      "[0.9181988  0.9176942  0.91472435 0.91456157 0.9200096 ]\n",
      "[0.9095512  0.90899396 0.90571284 0.9055313  0.9115434 ]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        sess.run(train_op, feed_dict={model.input: np.random.rand(32, 28, 28, 3), y_true: np.ones((32, 28, 28, 5))})\n",
    "        print(sess.run(moving_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
