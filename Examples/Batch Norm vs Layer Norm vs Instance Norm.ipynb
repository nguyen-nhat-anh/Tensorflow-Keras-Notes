{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ shape = (B, H, W, C)\n",
    "\n",
    "* batchnorm: $\\mu$ shape = (C, )\n",
    "\n",
    "$$\\mu_{\\cdot} = \\frac{1}{BHW} \\sum_{b,h,w} x_{b,h,w,\\cdot}$$\n",
    "\n",
    "* layernorm: $\\mu$ shape = (B, )\n",
    "\n",
    "$$\\mu_{\\cdot} = \\frac{1}{HWC} \\sum_{h,w,c} x_{\\cdot,h,w,c}$$\n",
    "\n",
    "* instance: $\\mu$ shape = (B, C)\n",
    "\n",
    "$$\\mu_{\\cdot,\\cdot} = \\frac{1}{HW} \\sum_{h,w} x_{\\cdot,h,w,\\cdot}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      " channel 0: \n",
      " [[0. 2.]\n",
      " [4. 6.]]\n",
      " channel 1: \n",
      " [[1. 3.]\n",
      " [5. 7.]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[ 8. 10.]\n",
      " [12. 14.]]\n",
      " channel 1: \n",
      " [[ 9. 11.]\n",
      " [13. 15.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.reshape(np.arange(16).astype('float32'), (2,2,2,2))\n",
    "def print_samples(x):\n",
    "    for i,sample in enumerate(x):\n",
    "        print('Sample {}:'.format(i))\n",
    "        for j in range(sample.shape[-1]):\n",
    "            print(' channel {}: \\n {}'.format(j, sample[:,:,j]))\n",
    "print_samples(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = tf.keras.layers.BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Batch Normalization:\n",
      "Sample 0:\n",
      " channel 0: \n",
      " [[-1.527489   -1.0910635 ]\n",
      " [-0.6546381  -0.21821271]]\n",
      " channel 1: \n",
      " [[-1.527489   -1.0910635 ]\n",
      " [-0.6546381  -0.21821271]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[0.21821271 0.6546381 ]\n",
      " [1.0910635  1.527489  ]]\n",
      " channel 1: \n",
      " [[0.21821271 0.6546381 ]\n",
      " [1.0910635  1.527489  ]]\n"
     ]
    }
   ],
   "source": [
    "y = batch_norm(x, training=True)\n",
    "# y = tf.contrib.layers.batch_norm(x)\n",
    "print('After Batch Normalization:')\n",
    "print_samples(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute manually:\n",
      "Sample 0:\n",
      " channel 0: \n",
      " [[-1.5275252  -1.0910894 ]\n",
      " [-0.65465367 -0.21821788]]\n",
      " channel 1: \n",
      " [[-1.5275252  -1.0910894 ]\n",
      " [-0.65465367 -0.21821788]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[0.21821788 0.65465367]\n",
      " [1.0910894  1.5275252 ]]\n",
      " channel 1: \n",
      " [[0.21821788 0.65465367]\n",
      " [1.0910894  1.5275252 ]]\n"
     ]
    }
   ],
   "source": [
    "y = (x - np.mean(x, axis=(0,1,2))[None,None,None,:]) / np.std(x, axis=(0,1,2))[None,None,None,:]\n",
    "print('Compute manually:')\n",
    "print_samples(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = tf.keras.layers.LayerNormalization(axis=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Layer Normalization:\n",
      "Sample 0:\n",
      " channel 0: \n",
      " [[-1.5273798 -0.6545913]\n",
      " [ 0.2181971  1.0909855]]\n",
      " channel 1: \n",
      " [[-1.0909855 -0.2181971]\n",
      " [ 0.6545913  1.5273798]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[-1.52738    -0.65459156]\n",
      " [ 0.21819687  1.0909853 ]]\n",
      " channel 1: \n",
      " [[-1.0909858  -0.21819735]\n",
      " [ 0.6545911   1.5273795 ]]\n"
     ]
    }
   ],
   "source": [
    "y = layer_norm(x)\n",
    "# y = tf.contrib.layers.layer_norm(x)\n",
    "print('After Layer Normalization:')\n",
    "print_samples(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute manually:\n",
      "Sample 0:\n",
      " channel 0: \n",
      " [[-1.5275252  -0.65465367]\n",
      " [ 0.21821788  1.0910894 ]]\n",
      " channel 1: \n",
      " [[-1.0910894  -0.21821788]\n",
      " [ 0.65465367  1.5275252 ]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[-1.5275252  -0.65465367]\n",
      " [ 0.21821788  1.0910894 ]]\n",
      " channel 1: \n",
      " [[-1.0910894  -0.21821788]\n",
      " [ 0.65465367  1.5275252 ]]\n"
     ]
    }
   ],
   "source": [
    "y = (x - np.mean(x, axis=(1,2,3))[:,None,None,None]) / np.std(x, axis=(1,2,3))[:,None,None,None]\n",
    "print('Compute manually:')\n",
    "print_samples(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_norm = tf.keras.layers.LayerNormalization(axis=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Instance Normalization:\n",
      "Sample 0:\n",
      " channel 0: \n",
      " [[-1.3415066  -0.4471689 ]\n",
      " [ 0.44716883  1.3415066 ]]\n",
      " channel 1: \n",
      " [[-1.3415066  -0.44716883]\n",
      " [ 0.44716895  1.3415066 ]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[-1.3415067  -0.44716883]\n",
      " [ 0.44716883  1.3415065 ]]\n",
      " channel 1: \n",
      " [[-1.3415065  -0.44716883]\n",
      " [ 0.44716883  1.3415065 ]]\n"
     ]
    }
   ],
   "source": [
    "y = instance_norm(x)\n",
    "# y = tf.contrib.layers.instance_norm(x)\n",
    "print('After Instance Normalization:')\n",
    "print_samples(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute manually:\n",
      "Sample 0:\n",
      " channel 0: \n",
      " [[-1.3416407 -0.4472136]\n",
      " [ 0.4472136  1.3416407]]\n",
      " channel 1: \n",
      " [[-1.3416407 -0.4472136]\n",
      " [ 0.4472136  1.3416407]]\n",
      "Sample 1:\n",
      " channel 0: \n",
      " [[-1.3416407 -0.4472136]\n",
      " [ 0.4472136  1.3416407]]\n",
      " channel 1: \n",
      " [[-1.3416407 -0.4472136]\n",
      " [ 0.4472136  1.3416407]]\n"
     ]
    }
   ],
   "source": [
    "y = (x - np.mean(x, axis=(1,2))[:,None,None,:]) / np.std(x, axis=(1,2))[:,None,None:]\n",
    "print('Compute manually:')\n",
    "print_samples(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
