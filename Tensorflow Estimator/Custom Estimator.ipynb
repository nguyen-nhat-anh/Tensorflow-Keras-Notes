{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "train = pd.read_csv('data/iris_training.csv', names=CSV_COLUMN_NAMES, header=0)\n",
    "train_x, train_y = train, train.pop('Species')\n",
    "train_x = train_x.to_dict(orient='list')\n",
    "train_y = train_y.values\n",
    "\n",
    "val = pd.read_csv('data/iris_test.csv', names=CSV_COLUMN_NAMES, header=0)\n",
    "val_x, val_y = val, val.pop('Species')\n",
    "val_x = val_x.to_dict(orient='list')\n",
    "val_y = val_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'])\n"
     ]
    }
   ],
   "source": [
    "print(train_x.keys())\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    tf.feature_column.numeric_column(key='SepalLength'),\n",
    "    tf.feature_column.numeric_column(key='SepalWidth'),\n",
    "    tf.feature_column.numeric_column(key='PetalLength'),\n",
    "    tf.feature_column.numeric_column(key='PetalWidth')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 3\n",
    "N_INPUT_FEATURES = 4\n",
    "BATCH_SIZE = 32\n",
    "STEPS=1000\n",
    "MODEL_DIR = 'model'\n",
    "EXPORT_DIR = os.path.join(MODEL_DIR, 'export', 'Servo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "    # Batch the examples.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "def predict_input_fn(features, batch_size):\n",
    "    \"\"\"An input function for prediction\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "\n",
    "    # Batch the examples.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "def serving_input_fn():\n",
    "    \"\"\"\n",
    "    An input funtion for serving\n",
    "    \n",
    "    Returns a `serving_input_receiver_fn` that \n",
    "    takes no argument and \n",
    "    returns a `tf.estimator.export.ServingInputReceiver` or `tf.estimator.export.TensorServingInputReceiver`.\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'SepalLength': tf.placeholder(shape=[None], dtype=tf.float32), \n",
    "        'SepalWidth': tf.placeholder(shape=[None], dtype=tf.float32),\n",
    "        'PetalLength': tf.placeholder(shape=[None], dtype=tf.float32), \n",
    "        'PetalWidth': tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "    }\n",
    "    return tf.estimator.export.build_raw_serving_input_receiver_fn(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0720 20:26:11.013882 17744 deprecation.py:323] From <ipython-input-6-fcd552b503b1>:4: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SepalLength': array([6.5, 4.4, 7.6, 4.9, 6.3], dtype=float32), 'SepalWidth': array([3. , 3.2, 3. , 3.1, 2.3], dtype=float32), 'PetalLength': array([5.8, 1.3, 6.6, 1.5, 4.4], dtype=float32), 'PetalWidth': array([2.2, 0.2, 2.1, 0.1, 1.3], dtype=float32)}\n",
      "[2 0 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "# test train_input_fn\n",
    "# -------------------\n",
    "dataset = train_input_fn(train_x, train_y, batch_size=5)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    f, l = sess.run(next_element)\n",
    "    print(f)\n",
    "    print(l)\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model function has the following call signature:\n",
    "\n",
    "`def model_fn(\n",
    "    features, # This is batch_features from input_fn\n",
    "    labels,   # This is batch_labels from input_fn\n",
    "    mode,     # An instance of tf.estimator.ModeKeys\n",
    "    params):  # Additional configuration, passed from tf.estimator.Estimator`\n",
    "    \n",
    "and returns an instance of `tf.estimator.EstimatorSpec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=(N_INPUT_FEATURES,)) # (None, N_INPUT_FEATURES)\n",
    "    x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(inputs) # (None, 10)\n",
    "    x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x) # (None, 10)\n",
    "    x = tf.keras.layers.Dense(n_classes)(x) # (None, 10)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 20:26:11.360229 17744 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5931164   0.28143415 -0.3913166 ]\n",
      " [-0.47901395  0.23427066 -0.39212173]\n",
      " [-0.48497716  0.27129757 -0.51716274]\n",
      " [-0.4879142   0.26547086 -0.46955964]\n",
      " [-2.8710532   0.57653165  1.0698833 ]]\n"
     ]
    }
   ],
   "source": [
    "# test create_model\n",
    "# -----------------\n",
    "model = create_model(3)\n",
    "\n",
    "dataset = train_input_fn(train_x, train_y, batch_size=5)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element, _ = iterator.get_next()\n",
    "\n",
    "inputs = tf.keras.layers.DenseFeatures(FEATURE_COLUMNS)(next_element) # (None, N_INPUT_FEATURES)\n",
    "logits = model(inputs) # (None, 3)\n",
    "\n",
    "var_init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)\n",
    "    print(logits.eval())\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the value of `mode`, different arguments for `tf.estimator.EstimatorSpec` are required. Namely\n",
    "* For `mode == ModeKeys.TRAIN`: required fields are `loss` and `train_op`.\n",
    "* For `mode == ModeKeys.EVAL`: required field is `loss`.\n",
    "* For `mode == ModeKeys.PREDICT`: required fields are `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    '''\n",
    "    inputs\n",
    "        features: This is batch_features (first output) from input_fn \n",
    "        labels: This is batch_labels (second output) from input_fn, shape (None,)\n",
    "        mode: An instance of tf.estimator.ModeKeys\n",
    "        params: Additional configuration, passed from tf.estimator.Estimator\n",
    "                For this example we only pass `n_classes`.\n",
    "    returns:\n",
    "        an instance of tf.estimator.EstimatorSpec\n",
    "    '''\n",
    "    model = create_model(params['n_classes'])\n",
    "    \n",
    "    inputs = tf.keras.layers.DenseFeatures(FEATURE_COLUMNS)(features) # shape (None, N_INPUT_FEATURES)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT: # only invoked when call tf.estimator.Estimator.predict\n",
    "        logits = model(inputs, \n",
    "                       training=False) # this param is used when there are layers (e.g. Dropout layers)\n",
    "                                       # that behave differently in training and inference\n",
    "        predictions = {\n",
    "            'classes': tf.math.argmax(logits, axis=1), # shape (None, )\n",
    "            'probabilities': tf.nn.softmax(logits) # shape (None, n_classes)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL: # only invoked when call tf.estimator.Estimator.evaluate\n",
    "        logits = model(inputs, \n",
    "                       training=False) # this param is used when there are layers (e.g. Dropout layers)\n",
    "                                       # that behave differently in training and inference\n",
    "        # Compute loss\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, # labels shape (None, )\n",
    "                                                      logits=logits) # logits shape (None, n_classes)  \n",
    "        # Compute predictions\n",
    "        predicted_classes = tf.math.argmax(logits, axis=1) # shape (None, )\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                       predictions=predicted_classes,\n",
    "                                       name='eval_accuracy')\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          loss=loss, \n",
    "                                          eval_metric_ops={'eval_accuracy': accuracy}) # record to Tensorboard\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN: # only invoked when call tf.estimator.Estimator.train\n",
    "        logits = model(inputs, \n",
    "                       training=True) # this param is used when there are layers (e.g. Dropout layers)\n",
    "                                       # that behave differently in training and inference\n",
    "        # Compute loss\n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, # labels shape (None, )\n",
    "                                                      logits=logits) # logits shape (None, n_classes)\n",
    "        \n",
    "        # Compute predictions\n",
    "        predicted_classes = tf.math.argmax(logits, axis=1) # shape (None, )\n",
    "        # Compute metrics\n",
    "        acc, acc_op = tf.metrics.accuracy(labels=labels,\n",
    "                                          predictions=predicted_classes,\n",
    "                                          name='train_accuracy')\n",
    "        # Record train accuracy to Tensorboard\n",
    "        tf.summary.scalar('train_accuracy', acc_op)\n",
    "        \n",
    "        # Create an optimizer and training op\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "        train_op = optimizer.minimize(loss, \n",
    "                                      global_step=tf.train.get_global_step()) # it's important to pass global_step\n",
    "                                                                              # to minimize() method in order to record\n",
    "                                                                              # the x-coordinate for Tensorboard graphs\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The custom Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                    model_dir=MODEL_DIR,\n",
    "                                    params={'n_classes': N_CLASSES}) # pass to model_fn params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 20:26:12.182610 17744 deprecation.py:323] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0720 20:26:12.304316 17744 deprecation.py:323] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0720 20:26:12.378116 17744 deprecation.py:506] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\training\\adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x21c31427438>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda: train_input_fn(train_x, train_y, batch_size=BATCH_SIZE), \n",
    "                 steps=STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wrap up our `input_fn` call in a `lambda` to capture the arguments while providing an input function that takes no arguments, as expected by the `Estimator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 20:26:14.911648 17744 deprecation.py:323] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: eval_input_fn(val_x, val_y, batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.96666664, 'loss': 0.05541057, 'global_step': 1000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 20:26:15.536814 17744 deprecation.py:323] From f:\\anaconda3\\envs\\tensorflow1.14\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'model\\\\export\\\\1563629175'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.export_saved_model(export_dir_base=EXPORT_DIR, serving_input_receiver_fn=serving_input_fn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = ['Setosa', 'Versicolor' , 'Virginica']\n",
    "test_y = ['Setosa', 'Versicolor', 'Virginica']\n",
    "test_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(input_fn=lambda: predict_input_fn(test_x, batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE 1:\n",
      "Prediction:  Setosa\n",
      "True:  Setosa\n",
      "Class `Setosa` confidence: 0.9991546869277954\n",
      "Class `Versicolor` confidence: 0.000845316331833601\n",
      "Class `Virginica` confidence: 1.3263680154196322e-09\n",
      "\n",
      "##################################################\n",
      "##################################################\n",
      "\n",
      "SAMPLE 2:\n",
      "Prediction:  Versicolor\n",
      "True:  Versicolor\n",
      "Class `Setosa` confidence: 0.00015223266382236034\n",
      "Class `Versicolor` confidence: 0.9976334571838379\n",
      "Class `Virginica` confidence: 0.0022142541129142046\n",
      "\n",
      "##################################################\n",
      "##################################################\n",
      "\n",
      "SAMPLE 3:\n",
      "Prediction:  Virginica\n",
      "True:  Virginica\n",
      "Class `Setosa` confidence: 3.49274927202714e-07\n",
      "Class `Versicolor` confidence: 0.10266430675983429\n",
      "Class `Virginica` confidence: 0.897335410118103\n",
      "\n",
      "##################################################\n",
      "##################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (true, pred) in enumerate(zip(test_y, predictions)):\n",
    "    print('SAMPLE {}:'.format(i+1))\n",
    "    print('Prediction: ', class_name[pred['classes']])\n",
    "    print('True: ', test_y[i])\n",
    "    for c in range(N_CLASSES):\n",
    "        print('Class `{}` confidence: {}'.format(class_name[c], pred['probabilities'][c]))\n",
    "    \n",
    "    print('\\n##################################################')\n",
    "    print('##################################################\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
