{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/tf_records\n",
    "\n",
    "* The <b>TFRecord format</b> (`.tfrecord`) is a simple format for storing a sequence of binary records.\n",
    "\n",
    "* <b>Protocol buffers</b> are a cross-platform, cross-language library for efficient serialization of structured data.\n",
    "  \n",
    "  Protocol messages are defined by `.proto` files, these are often the easiest way to understand a message type.\n",
    "  \n",
    "* The `tf.Example` message (or protobuf) is a flexible message type that represents a `{\"string\": value}` mapping. It is designed for use with TensorFlow and is used throughout the higher-level APIs such as TFX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types for `tf.Example`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fundamentally a `tf.Example` is a `{\"string\": tf.train.Feature}` mapping.\n",
    "* The `tf.train.Feature` message type can accept one of the following three types\n",
    "  1. `tf.train.BytesList`\n",
    "     * `string`\n",
    "     * `byte`\n",
    "  2. `tf.train.FloatList`\n",
    "     * `float32` (`float`)\n",
    "     * `float64` (`double`)\n",
    "  3. `tf.train.Int64List`\n",
    "     * `bool`\n",
    "     * `enum`\n",
    "     * `int32`\n",
    "     * `uint32`\n",
    "     * `int64`\n",
    "     * `uint64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"test_string\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"test_bytes\"\n",
      "}\n",
      "\n",
      "float_list {\n",
      "  value: 2.7182817459106445\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature(u'test_bytes'.encode('utf-8')))\n",
    "\n",
    "print(_float_feature(np.exp(1)))\n",
    "\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All proto messages can be serialized to a binary-string using the `.SerializeToString()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x12\\x06\\n\\x04T\\xf8-@'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = _float_feature(np.exp(1))\n",
    "\n",
    "feature.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a `tf.Example` message from existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Within each observation, each value needs to be converted to a `tf.train.Feature` containing one of the 3 compatible types, using one of the functions above.\n",
    "\n",
    "2. Create a map (dictionary) from the feature name string to the <b>encoded feature value</b> produced in #1.\n",
    "\n",
    "3. The map produced in #2 is converted to a <b>Features message</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of observations in the dataset\n",
    "n_observations = int(1e4)\n",
    "\n",
    "# boolean feature, encoded as False or True\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# integer feature, random from 0 .. 4\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# string feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# float feature, from a standard normal distribution\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    \"\"\"\n",
    "    Creates a tf.Example message ready to be written to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "    # data type.\n",
    "\n",
    "    feature = {\n",
    "      'feature0': _int64_feature(feature0),\n",
    "      'feature1': _int64_feature(feature1),\n",
    "      'feature2': _bytes_feature(feature2),\n",
    "      'feature3': _float_feature(feature3),\n",
    "    }\n",
    "\n",
    "    # Create a Features message using tf.train.Example.\n",
    "\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: Use `tf.train.Features` to create a dictionary of `tf.train.Feature`, then pass it to the `features` arg of `tf.train.Example`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\nR\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04[\\xd3|?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an example observation from the dataset.\n",
    "\n",
    "example_observation = []\n",
    "\n",
    "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decode the message use the `tf.train.Example.FromString()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"feature0\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature1\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature2\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"goat\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature3\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 0.9876000285148621\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_proto = tf.train.Example.FromString(serialized_example)\n",
    "example_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord files using `tf.io`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the `tf.Example` observations to the file.\n",
    "with tf.io.TFRecordWriter(os.path.join(data_dir, 'test.tfrecords')) as writer:\n",
    "    for i in range(n_observations):\n",
    "        example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0803 00:27:21.795620 16272 deprecation.py:323] From <ipython-input-11-3cfec0d824f4>:2: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"feature0\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"feature1\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"feature2\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"cat\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"feature3\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.4755978286266327\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an record iterator\n",
    "record_iterator = tf.io.tf_record_iterator(os.path.join(data_dir, 'test.tfrecords'))\n",
    "\n",
    "# Iterate through the TFRecords\n",
    "for string_record in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record) # decode the record message\n",
    "    print(example)\n",
    "    # Exit after 1 iteration as this is purely demonstrative.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading into `tf.data.TFRecordDataset` using `tf.parse_single_example()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "feature_description = {\n",
    "    'feature0': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    return tf.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: you can use `tf.parse_example()` to parse a whole batch at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tfrecord files into a TFRecordDataset\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames=[os.path.join(data_dir, 'test.tfrecords')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0803 00:27:22.213502 16272 deprecation.py:323] From <ipython-input-14-708667d8f491>:3: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw example:  b'\\nQ\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x8f\\x81\\xf3>\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00'\n",
      "Parsed example:  {'feature0': 1, 'feature1': 0, 'feature2': b'cat', 'feature3': 0.47559783}\n"
     ]
    }
   ],
   "source": [
    "# Test _parse_funtion\n",
    "# -------------------\n",
    "iterator = raw_dataset.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()\n",
    "parsed_item = _parse_function(next_item)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    raw_value, parsed_value = sess.run([next_item, parsed_item])\n",
    "    print('Raw example: ', raw_value)\n",
    "    print('Parsed example: ', parsed_value)\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply parse function to each item in the dataset using the `tf.data.Dataset.map()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': 1, 'feature1': 0, 'feature2': b'cat', 'feature3': 0.47559783}\n"
     ]
    }
   ],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "next_item = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_item))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
