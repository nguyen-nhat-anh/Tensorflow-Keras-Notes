{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://aws.amazon.com/blogs/machine-learning/bring-your-own-pre-trained-mxnet-or-tensorflow-models-into-amazon-sagemaker/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After training a custom estimator, the model is saved in an exportable format using `tf.estimator.Estimator.export_saved_model()` method (see \"Tensorflow Estimator/Custom Estimator.ipynb\" for more details).\n",
    "* Move the TensorFlow exported model into a directory export\\Servo. Amazon SageMaker will recognize this as a loadable TensorFlow model. Your directory and file structure should look like this:\n",
    "![SegmentLocal](resources/pre-trained-models-sagemaker-2.gif)\n",
    "* SavedModel directory structure:\n",
    "![SegmentLocal](resources/1.png)\n",
    "* Model inputs and outputs:\n",
    "\n",
    "`The given SavedModel SignatureDef contains the following input(s):\n",
    "  inputs['PetalLength'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1)\n",
    "      name: Placeholder_2:0\n",
    "  inputs['PetalWidth'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1)\n",
    "      name: Placeholder_3:0\n",
    "  inputs['SepalLength'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1)\n",
    "      name: Placeholder:0\n",
    "  inputs['SepalWidth'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1)\n",
    "      name: Placeholder_1:0\n",
    "The given SavedModel SignatureDef contains the following output(s):\n",
    "  outputs['classes'] tensor_info:\n",
    "      dtype: DT_INT64\n",
    "      shape: (-1)\n",
    "      name: ArgMax:0\n",
    "  outputs['probabilities'] tensor_info:\n",
    "      dtype: DT_FLOAT\n",
    "      shape: (-1, 3)\n",
    "      name: Softmax:0\n",
    "Method name is: tensorflow/serving/predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an overview of the entire process.\n",
    "\n",
    "* Step 1: Model definitions are written in a framework of choice.\n",
    "* Step 2: The model is trained in that framework.\n",
    "* Step 3: The model is exported and model artifacts that can be understood by Amazon SageMaker are created.\n",
    "* Step 4: Model artifacts are uploaded to an Amazon S3 bucket.\n",
    "* Step 5: Using the model definitions, artifacts, and the Amazon SageMaker Python SDK, a SageMaker model is created.\n",
    "* Step 6: The SageMaker model is deployed as an endpoint.\n",
    "\n",
    "![SegmentLocal](resources/pre-trained-models-sagemaker-1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload model artifacts to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tar the entire model directory (`export` directory) and upload to Amazon S3\n",
    "\n",
    "* Tar the model directory\n",
    "\n",
    "```python\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "export_model_dir = os.path.join('model','export')\n",
    "model_artifact_path = os.path.join('model', 'aws', 'model.tar.gz')\n",
    "with tarfile.open(model_artifact_path, mode='w:gz') as archive:\n",
    "    archive.add(export_model_dir, recursive=True)\n",
    "```\n",
    "\n",
    "* Create an Amazon S3 Bucket (skip this step if you had already created an S3 bucket)\n",
    "\n",
    "  https://docs.aws.amazon.com/sagemaker/latest/dg/gs-config-permissions.html\n",
    "  \n",
    "  Go to aws console (https://console.aws.amazon.com). Select <b>Services</b>. Select <b>Storage/S3</b> and create a bucket\n",
    "  \n",
    "  Note: Include \"sagemaker\" in the bucket name. For example, \"sagemaker-<i>[datetime]</i>\".\n",
    "  \n",
    "* Upload model artifacts (`model.tar.gz`) to the S3 bucket.\n",
    "\n",
    "  Model path example:\n",
    "  \n",
    "  `s3://sagemaker-22072019/tensorflow-custom-estimator/iris/model/model.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy from model artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an Amazon SageMaker Notebook Instance\n",
    "\n",
    "  https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html\n",
    "\n",
    "  1. Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\n",
    "  2. Choose <b>Notebook instances</b>, then choose <b>Create notebook instance</b>.\n",
    "  3. On the <b>Create notebook instance</b> page, provide the following information (if a field is not mentioned, leave the default values):\n",
    "    * For <b>Notebook instance name</b>, type a name for your notebook instance. E.g. `Deploy-pretrained-iris-custom-estimator`\n",
    "    * For Instance type, choose `ml.t2.medium`.\n",
    "    * For IAM role, choose Create a new role, then choose Create role. The IAM role you create will have permission to access to any S3 bucket with \"sagemaker\" in the name\n",
    "  4. Launch and create a new notebook\n",
    "\n",
    "* Deploying directly from model artifacts\n",
    "\n",
    "```python\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "role = get_execution_role()\n",
    "model = Model(model_data='s3://sagemaker-22072019/tensorflow-custom-estimator/iris/model/model.tar.gz', \n",
    "              role=role, framework_version='1.13')\n",
    "              \n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions against a SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "inputs = {\n",
    "    \"instances\": \n",
    "    [{\"SepalLength\": 6.4, \"SepalWidth\": 2.8, \"PetalLength\": 5.6, \"PetalWidth\": 2.2},\n",
    "     {\"SepalLength\": 4.9, \"SepalWidth\": 3.1, \"PetalLength\": 1.5, \"PetalWidth\": 0.1}]\n",
    "}\n",
    "result = predictor.predict(inputs)\n",
    "print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`{\n",
    "    'predictions': [{'probabilities': [1.02038e-09, 0.000515907, 0.999484], 'classes': 2},\n",
    "                    {'probabilities': [0.999027, 0.000972887, 1.89823e-09], 'classes': 0}]\n",
    "}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Postman to test the api\n",
    "* Get your access key and secret key for authorization\n",
    "  * Open the Amazon IAM console at https://console.aws.amazon.com/iam/.\n",
    "  * Choose <b>Users</b> and select your user\n",
    "  * Choose <b>Security credentials</b>, then choose <b>Create access key</b>\n",
    "  * Get your access key and secret key.\n",
    "* Get the endpoint url\n",
    "  * Open the Amazon SageMaker console at https://console.aws.amazon.com/sagemaker/.\n",
    "  * Choose <b>Endpoints</b>, then choose your deployed model endpoint.\n",
    "  * Get the endpoint url\n",
    "* Launch Postman:\n",
    "  * For <b>Authorization</b>, choose <b>AWS Signature</b>\n",
    "    * Enter your AccessKey and SecretKey.\n",
    "    * For AWS Region, enter your region.\n",
    "    * For Service Name, enter \"sagemaker\"\n",
    "  * For url, enter the endpoint url. Use the POST method.\n",
    "  * For message body, enter\n",
    "```json\n",
    "{\n",
    "    \"instances\": [\n",
    "        {\n",
    "            \"SepalLength\": 6.4,\n",
    "            \"SepalWidth\": 2.8,\n",
    "            \"PetalLength\": 5.6,\n",
    "            \"PetalWidth\": 2.2\n",
    "        },\n",
    "        {\n",
    "            \"SepalLength\": 4.9,\n",
    "            \"SepalWidth\": 3.1,\n",
    "            \"PetalLength\": 1.5,\n",
    "            \"PetalWidth\": 0.1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"predictions\": [\n",
    "        {\n",
    "            \"probabilities\": [\n",
    "                1.02038e-9,\n",
    "                0.000515907,\n",
    "                0.999484\n",
    "            ],\n",
    "            \"classes\": 2\n",
    "        },\n",
    "        {\n",
    "            \"probabilities\": [\n",
    "                0.999027,\n",
    "                0.000972887,\n",
    "                1.89823e-9\n",
    "            ],\n",
    "            \"classes\": 0\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
